{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "760772f3",
   "metadata": {},
   "source": [
    "### Author: Arpita Das, TUID: 916103845\n",
    "### Final Project, ECE 8110 (Applied Machine Learning for Cyber Security), Spring 2024\n",
    "### Date: 05/07/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503c5368",
   "metadata": {},
   "source": [
    "## Please note that for the sake of achieving parallel results, the work was done parallely in two parts (DistilBERT and RoBERTA) and then merged later. This is the merged version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbba0105",
   "metadata": {},
   "source": [
    "### The data is located at https://github.com/arpita-das-CUET/Large-Language-Model-Approach-to-Detect-Phishing-and-Safe-Emails "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3b5711",
   "metadata": {},
   "source": [
    "# Phishing Detection Using DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8b36b28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:26:39.548195Z",
     "iopub.status.busy": "2023-07-12T14:26:39.547844Z",
     "iopub.status.idle": "2023-07-12T14:26:59.569528Z",
     "shell.execute_reply": "2023-07-12T14:26:59.567996Z",
     "shell.execute_reply.started": "2023-07-12T14:26:39.548164Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q mlflow nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b7332ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:26:59.573180Z",
     "iopub.status.busy": "2023-07-12T14:26:59.572738Z",
     "iopub.status.idle": "2023-07-12T14:27:14.905100Z",
     "shell.execute_reply": "2023-07-12T14:27:14.904104Z",
     "shell.execute_reply.started": "2023-07-12T14:26:59.573136Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import gc\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import TextDataset, LineByLineTextDataset, DataCollatorForLanguageModeling, \\\n",
    "pipeline, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from nlp import Dataset\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import datasets\n",
    "from transformers import pipeline\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4f61811",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:27:14.907617Z",
     "iopub.status.busy": "2023-07-12T14:27:14.906577Z",
     "iopub.status.idle": "2023-07-12T14:27:14.916515Z",
     "shell.execute_reply": "2023-07-12T14:27:14.915586Z",
     "shell.execute_reply.started": "2023-07-12T14:27:14.907578Z"
    }
   },
   "outputs": [],
   "source": [
    "# set parameters\n",
    "train_fraction = 0.8 # fraction of a dataset used for training (the rest used for validation)\n",
    "num_train_epochs = 3 # epochs to train\n",
    "batch_size = 16 # batch size for training and validation\n",
    "warmup_steps = 50\n",
    "weight_decay = 0.02\n",
    "BERT_MODEL = \"distilbert-base-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec2dbd86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:27:14.918308Z",
     "iopub.status.busy": "2023-07-12T14:27:14.917918Z",
     "iopub.status.idle": "2023-07-12T14:27:16.037379Z",
     "shell.execute_reply": "2023-07-12T14:27:16.036479Z",
     "shell.execute_reply.started": "2023-07-12T14:27:14.918273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17539, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12206</th>\n",
       "      <th>2702</th>\n",
       "      <th>11296</th>\n",
       "      <th>564</th>\n",
       "      <th>11429</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Email Text</th>\n",
       "      <td>On Monday 22 July 2002 07:00 CET John Rudd wro...</td>\n",
       "      <td>**Dublin**: something from the archives. Daev ...</td>\n",
       "      <td>fw : cms rfp response fyi - - - - - - original...</td>\n",
       "      <td>Joseph S. Barrera III:\\n&gt;I just use the free/a...</td>\n",
       "      <td>re : cp &amp; l daren : when you get a chance , st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Email Type</th>\n",
       "      <td>Safe Email</td>\n",
       "      <td>Safe Email</td>\n",
       "      <td>Safe Email</td>\n",
       "      <td>Safe Email</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        12206  \\\n",
       "Email Text  On Monday 22 July 2002 07:00 CET John Rudd wro...   \n",
       "Email Type                                         Safe Email   \n",
       "\n",
       "                                                        2702   \\\n",
       "Email Text  **Dublin**: something from the archives. Daev ...   \n",
       "Email Type                                         Safe Email   \n",
       "\n",
       "                                                        11296  \\\n",
       "Email Text  fw : cms rfp response fyi - - - - - - original...   \n",
       "Email Type                                         Safe Email   \n",
       "\n",
       "                                                        564    \\\n",
       "Email Text  Joseph S. Barrera III:\\n>I just use the free/a...   \n",
       "Email Type                                         Safe Email   \n",
       "\n",
       "                                                        11429  \n",
       "Email Text  re : cp & l daren : when you get a chance , st...  \n",
       "Email Type                                         Safe Email  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/CSNAP/Downloads/Final Project_ECE 8110/Phishing_Email.csv\").drop(['Unnamed: 0'], axis=1).drop_duplicates()\n",
    "print(df.shape)\n",
    "df.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8d4ba6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:27:16.041480Z",
     "iopub.status.busy": "2023-07-12T14:27:16.040808Z",
     "iopub.status.idle": "2023-07-12T14:27:16.068980Z",
     "shell.execute_reply": "2023-07-12T14:27:16.067998Z",
     "shell.execute_reply.started": "2023-07-12T14:27:16.041440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17539, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14439</th>\n",
       "      <td>I've been testing Razor, invoked from sendmail...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4179</th>\n",
       "      <td>only if you are serious . . . will i help you ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18158</th>\n",
       "      <td>fw : can you check a deal for me bill , this e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11429</th>\n",
       "      <td>re : cp &amp; l daren : when you get a chance , st...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12167</th>\n",
       "      <td>What I understood was that the activists on th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13000</th>\n",
       "      <td>re : xbtkvi , the ala admitted banned cd gover...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9157</th>\n",
       "      <td>How do I install / add an additional service p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>re [ 10 ] : i trust you at six male paranormal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15245</th>\n",
       "      <td>macromedia dreamweaver mx 2004 plus templates ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12336</th>\n",
       "      <td>largest collection of dowlnoadable porn d \\ / ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14965</th>\n",
       "      <td>enhance your anatomy within a few days you sho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17333</th>\n",
       "      <td>On Fri, 13 Sep 2002, Dale Alspach wrote:\\n&gt; My...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2371</th>\n",
       "      <td>make money at home with ebay ! order confirmat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>\\nThe way to debug something like this is to t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13046</th>\n",
       "      <td>featured profile running at the right time pen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>increase your penis size yes . . it is possibl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13377</th>\n",
       "      <td>URL: http://www.newsisfree.com/click/-2,842319...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14163</th>\n",
       "      <td>\" syntax and the comparative method concerning...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14143</th>\n",
       "      <td>dowlnoad 70 + full lenght p 0 r n movies - x 5...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6152</th>\n",
       "      <td>call for papers : panel on telephone calls pan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  label\n",
       "14439  I've been testing Razor, invoked from sendmail...      0\n",
       "4179   only if you are serious . . . will i help you ...      1\n",
       "18158  fw : can you check a deal for me bill , this e...      0\n",
       "11429  re : cp & l daren : when you get a chance , st...      0\n",
       "12167  What I understood was that the activists on th...      0\n",
       "13000  re : xbtkvi , the ala admitted banned cd gover...      1\n",
       "9157   How do I install / add an additional service p...      0\n",
       "138    re [ 10 ] : i trust you at six male paranormal...      1\n",
       "15245  macromedia dreamweaver mx 2004 plus templates ...      1\n",
       "12336  largest collection of dowlnoadable porn d \\ / ...      1\n",
       "14965  enhance your anatomy within a few days you sho...      1\n",
       "17333  On Fri, 13 Sep 2002, Dale Alspach wrote:\\n> My...      0\n",
       "2371   make money at home with ebay ! order confirmat...      1\n",
       "1730   \\nThe way to debug something like this is to t...      0\n",
       "13046  featured profile running at the right time pen...      1\n",
       "103    increase your penis size yes . . it is possibl...      1\n",
       "13377  URL: http://www.newsisfree.com/click/-2,842319...      0\n",
       "14163  \" syntax and the comparative method concerning...      0\n",
       "14143  dowlnoad 70 + full lenght p 0 r n movies - x 5...      1\n",
       "6152   call for papers : panel on telephone calls pan...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create target\n",
    "df['label'] = (df['Email Type']==\"Phishing Email\").astype(int)\n",
    "df['title'] = df['Email Text']\n",
    "df = df[['title', 'label']]\n",
    "\n",
    "print(df.shape)\n",
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8af377e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:27:16.041480Z",
     "iopub.status.busy": "2023-07-12T14:27:16.040808Z",
     "iopub.status.idle": "2023-07-12T14:27:16.068980Z",
     "shell.execute_reply": "2023-07-12T14:27:16.067998Z",
     "shell.execute_reply.started": "2023-07-12T14:27:16.041440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17539, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14439</th>\n",
       "      <td>I've been testing Razor, invoked from sendmail...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4179</th>\n",
       "      <td>only if you are serious . . . will i help you ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18158</th>\n",
       "      <td>fw : can you check a deal for me bill , this e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11429</th>\n",
       "      <td>re : cp &amp; l daren : when you get a chance , st...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12167</th>\n",
       "      <td>What I understood was that the activists on th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13000</th>\n",
       "      <td>re : xbtkvi , the ala admitted banned cd gover...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9157</th>\n",
       "      <td>How do I install / add an additional service p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>re [ 10 ] : i trust you at six male paranormal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15245</th>\n",
       "      <td>macromedia dreamweaver mx 2004 plus templates ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12336</th>\n",
       "      <td>largest collection of dowlnoadable porn d \\ / ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14965</th>\n",
       "      <td>enhance your anatomy within a few days you sho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17333</th>\n",
       "      <td>On Fri, 13 Sep 2002, Dale Alspach wrote:\\n&gt; My...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2371</th>\n",
       "      <td>make money at home with ebay ! order confirmat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>\\nThe way to debug something like this is to t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13046</th>\n",
       "      <td>featured profile running at the right time pen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>increase your penis size yes . . it is possibl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13377</th>\n",
       "      <td>URL: http://www.newsisfree.com/click/-2,842319...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14163</th>\n",
       "      <td>\" syntax and the comparative method concerning...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14143</th>\n",
       "      <td>dowlnoad 70 + full lenght p 0 r n movies - x 5...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6152</th>\n",
       "      <td>call for papers : panel on telephone calls pan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  label\n",
       "14439  I've been testing Razor, invoked from sendmail...      0\n",
       "4179   only if you are serious . . . will i help you ...      1\n",
       "18158  fw : can you check a deal for me bill , this e...      0\n",
       "11429  re : cp & l daren : when you get a chance , st...      0\n",
       "12167  What I understood was that the activists on th...      0\n",
       "13000  re : xbtkvi , the ala admitted banned cd gover...      1\n",
       "9157   How do I install / add an additional service p...      0\n",
       "138    re [ 10 ] : i trust you at six male paranormal...      1\n",
       "15245  macromedia dreamweaver mx 2004 plus templates ...      1\n",
       "12336  largest collection of dowlnoadable porn d \\ / ...      1\n",
       "14965  enhance your anatomy within a few days you sho...      1\n",
       "17333  On Fri, 13 Sep 2002, Dale Alspach wrote:\\n> My...      0\n",
       "2371   make money at home with ebay ! order confirmat...      1\n",
       "1730   \\nThe way to debug something like this is to t...      0\n",
       "13046  featured profile running at the right time pen...      1\n",
       "103    increase your penis size yes . . it is possibl...      1\n",
       "13377  URL: http://www.newsisfree.com/click/-2,842319...      0\n",
       "14163  \" syntax and the comparative method concerning...      0\n",
       "14143  dowlnoad 70 + full lenght p 0 r n movies - x 5...      1\n",
       "6152   call for papers : panel on telephone calls pan...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create target\n",
    "df['label'] = (df['Email Type']==\"Phishing Email\").astype(int)\n",
    "df['title'] = df['Email Text']\n",
    "df = df[['title', 'label']]\n",
    "\n",
    "print(df.shape)\n",
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98eb9363",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:27:16.070974Z",
     "iopub.status.busy": "2023-07-12T14:27:16.070414Z",
     "iopub.status.idle": "2023-07-12T14:27:16.082985Z",
     "shell.execute_reply": "2023-07-12T14:27:16.082007Z",
     "shell.execute_reply.started": "2023-07-12T14:27:16.070940Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop null records\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8354edeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:27:16.084938Z",
     "iopub.status.busy": "2023-07-12T14:27:16.084486Z",
     "iopub.status.idle": "2023-07-12T14:27:16.094157Z",
     "shell.execute_reply": "2023-07-12T14:27:16.093201Z",
     "shell.execute_reply.started": "2023-07-12T14:27:16.084907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37393089291823467"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63e9d9e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:27:16.095879Z",
     "iopub.status.busy": "2023-07-12T14:27:16.095538Z",
     "iopub.status.idle": "2023-07-12T14:27:16.433040Z",
     "shell.execute_reply": "2023-07-12T14:27:16.432137Z",
     "shell.execute_reply.started": "2023-07-12T14:27:16.095847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21960, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random oversampling of minority class - not needed because of adding weights to minority class\n",
    "y = df[['label']]\n",
    "df = df.drop(['label'], axis=1)\n",
    "ros = RandomOverSampler(random_state=83)\n",
    "df, y_resampled = ros.fit_resample(df, y)\n",
    "del y\n",
    "df['label'] = y_resampled\n",
    "print(df.shape)\n",
    "del y_resampled\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de63c0b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:27:16.435134Z",
     "iopub.status.busy": "2023-07-12T14:27:16.434519Z",
     "iopub.status.idle": "2023-07-12T14:27:16.563361Z",
     "shell.execute_reply": "2023-07-12T14:27:16.562293Z",
     "shell.execute_reply.started": "2023-07-12T14:27:16.435098Z"
    }
   },
   "outputs": [],
   "source": [
    "medium_dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d369eda4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:27:16.565114Z",
     "iopub.status.busy": "2023-07-12T14:27:16.564760Z",
     "iopub.status.idle": "2023-07-12T14:27:16.887809Z",
     "shell.execute_reply": "2023-07-12T14:27:16.886821Z",
     "shell.execute_reply.started": "2023-07-12T14:27:16.565080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5da9e62b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:27:16.890504Z",
     "iopub.status.busy": "2023-07-12T14:27:16.889689Z",
     "iopub.status.idle": "2023-07-12T14:27:18.190279Z",
     "shell.execute_reply": "2023-07-12T14:27:18.189304Z",
     "shell.execute_reply.started": "2023-07-12T14:27:16.890467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52afa97f7d954704bbe2be7211ddbccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "443fa08f07854c9c81fb3a68d11384eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e349c9f6a5446d18a88b4def67479ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d177de33b4884b99916b5df139d21f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL, use_fast=True, low_cpu_mem_usage=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9733a32d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:27:18.193943Z",
     "iopub.status.busy": "2023-07-12T14:27:18.193656Z",
     "iopub.status.idle": "2023-07-12T14:28:17.797579Z",
     "shell.execute_reply": "2023-07-12T14:28:17.796447Z",
     "shell.execute_reply.started": "2023-07-12T14:27:18.193917Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76cb455feed4b65a0d8b2c26323db6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# simple function to batch tokenize utterances with truncation\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"title\"], truncation=True)\n",
    "\n",
    "medium_dataset = medium_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afb0552e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:28:17.799579Z",
     "iopub.status.busy": "2023-07-12T14:28:17.799104Z",
     "iopub.status.idle": "2023-07-12T14:28:46.662660Z",
     "shell.execute_reply": "2023-07-12T14:28:46.661736Z",
     "shell.execute_reply.started": "2023-07-12T14:28:17.799542Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cdfe3e50f6a4154a256eea485120f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddccda5575034ca082035cf9fe3abb00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset has a built in train test split method\n",
    "medium_dataset = medium_dataset.train_test_split(test_size=1-train_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f82ba2a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:28:46.669596Z",
     "iopub.status.busy": "2023-07-12T14:28:46.668896Z",
     "iopub.status.idle": "2023-07-12T14:28:46.676952Z",
     "shell.execute_reply": "2023-07-12T14:28:46.675944Z",
     "shell.execute_reply.started": "2023-07-12T14:28:46.669560Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset(features: {'title': Value(dtype='string', id=None), 'label': Value(dtype='int64', id=None), 'input_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}, num_rows: 17568),\n",
       " 'test': Dataset(features: {'title': Value(dtype='string', id=None), 'label': Value(dtype='int64', id=None), 'input_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}, num_rows: 4392)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d52a31de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:28:46.683313Z",
     "iopub.status.busy": "2023-07-12T14:28:46.680164Z",
     "iopub.status.idle": "2023-07-12T14:28:46.691263Z",
     "shell.execute_reply": "2023-07-12T14:28:46.689988Z",
     "shell.execute_reply.started": "2023-07-12T14:28:46.683275Z"
    }
   },
   "outputs": [],
   "source": [
    "medium_dataset.remove_column_(\"title\")  # remove the text column because we don't need to keep it in memory anymore\n",
    "# this is not required but speeds things up a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbe639fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:28:46.696991Z",
     "iopub.status.busy": "2023-07-12T14:28:46.696135Z",
     "iopub.status.idle": "2023-07-12T14:28:46.705314Z",
     "shell.execute_reply": "2023-07-12T14:28:46.704263Z",
     "shell.execute_reply.started": "2023-07-12T14:28:46.696955Z"
    }
   },
   "outputs": [],
   "source": [
    "# DataCollatorWithPadding creates batch of data. It also dynamically pads text to the \n",
    "#  length of the longest element in the batch, making them all the same length. \n",
    "#  It's possible to pad your text in the tokenizer function with padding=True, dynamic padding is more efficient.\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4cf92ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:28:46.707816Z",
     "iopub.status.busy": "2023-07-12T14:28:46.707158Z",
     "iopub.status.idle": "2023-07-12T14:28:46.721215Z",
     "shell.execute_reply": "2023-07-12T14:28:46.720251Z",
     "shell.execute_reply.started": "2023-07-12T14:28:46.707784Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] <! - - a { text - decoration : none } - - > V. I. P Animal lovers club invite new members! No shit! Only REAL ANIMAL porn! Our super active members send home video and photos every day! Don't miss this offer! CLICK to JOIN US! [ remove my email from mail list ] http : / / xent. com / mailman / listinfo / fork [SEP]\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(medium_dataset['train'][0]['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f6f831",
   "metadata": {},
   "source": [
    "### Loading and training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a381834b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:28:46.724343Z",
     "iopub.status.busy": "2023-07-12T14:28:46.722780Z",
     "iopub.status.idle": "2023-07-12T14:28:49.838948Z",
     "shell.execute_reply": "2023-07-12T14:28:49.838098Z",
     "shell.execute_reply.started": "2023-07-12T14:28:46.724305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f7f5a5d766843e7b26bd83d4bb06f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/263M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    BERT_MODEL, num_labels=2,\n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "model.config.id2label = {0: 'SAVE EMAIL', 1: 'PHISHING EMAIL'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4337dcc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:28:49.845408Z",
     "iopub.status.busy": "2023-07-12T14:28:49.843024Z",
     "iopub.status.idle": "2023-07-12T14:28:49.855329Z",
     "shell.execute_reply": "2023-07-12T14:28:49.854388Z",
     "shell.execute_reply.started": "2023-07-12T14:28:49.845371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.783042\n"
     ]
    }
   ],
   "source": [
    "# number of trainable parameters\n",
    "print(model.num_parameters(only_trainable=True)/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca345e8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:28:49.861787Z",
     "iopub.status.busy": "2023-07-12T14:28:49.858391Z",
     "iopub.status.idle": "2023-07-12T14:28:50.353143Z",
     "shell.execute_reply": "2023-07-12T14:28:50.352091Z",
     "shell.execute_reply.started": "2023-07-12T14:28:49.861752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8412d1da17043c89625ece11b1a671b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2698d134",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:28:50.360588Z",
     "iopub.status.busy": "2023-07-12T14:28:50.358115Z",
     "iopub.status.idle": "2023-07-12T14:28:56.125129Z",
     "shell.execute_reply": "2023-07-12T14:28:56.124115Z",
     "shell.execute_reply.started": "2023-07-12T14:28:50.360548Z"
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    logging_dir='./logs',\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    logging_strategy='steps',\n",
    "    logging_first_step=True,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=1,\n",
    "    evaluation_strategy='epoch',\n",
    "    warmup_steps=warmup_steps,\n",
    "    weight_decay=weight_decay,\n",
    "    eval_steps=1,\n",
    "    save_strategy='epoch',\n",
    "    report_to=\"mlflow\",  # log to mlflow\n",
    ")\n",
    "\n",
    "# Define the trainer: \n",
    "# instantiate the trainer class and check for available devices\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=medium_dataset['train'],\n",
    "    eval_dataset=medium_dataset['test'],\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc9e10ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:28:56.128377Z",
     "iopub.status.busy": "2023-07-12T14:28:56.127973Z",
     "iopub.status.idle": "2023-07-12T14:29:38.755978Z",
     "shell.execute_reply": "2023-07-12T14:29:38.755036Z",
     "shell.execute_reply.started": "2023-07-12T14:28:56.128340Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='550' max='275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [275/275 09:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.694774866104126,\n",
       " 'eval_accuracy': 0.4822404371584699,\n",
       " 'eval_runtime': 42.5773,\n",
       " 'eval_samples_per_second': 103.154,\n",
       " 'eval_steps_per_second': 6.459}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get initial metrics\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28e92572",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:29:38.757757Z",
     "iopub.status.busy": "2023-07-12T14:29:38.757420Z",
     "iopub.status.idle": "2023-07-12T14:55:35.252171Z",
     "shell.execute_reply": "2023-07-12T14:55:35.251032Z",
     "shell.execute_reply.started": "2023-07-12T14:29:38.757725Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3294' max='3294' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3294/3294 25:55, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.046590</td>\n",
       "      <td>0.988843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.037073</td>\n",
       "      <td>0.993625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.038644</td>\n",
       "      <td>0.992714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3294, training_loss=0.04472334078184669, metrics={'train_runtime': 1556.455, 'train_samples_per_second': 33.862, 'train_steps_per_second': 2.116, 'total_flos': 6976623228559680.0, 'train_loss': 0.04472334078184669, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a53afdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:55:35.254806Z",
     "iopub.status.busy": "2023-07-12T14:55:35.253954Z",
     "iopub.status.idle": "2023-07-12T14:56:16.658225Z",
     "shell.execute_reply": "2023-07-12T14:56:16.657128Z",
     "shell.execute_reply.started": "2023-07-12T14:55:35.254755Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='275' max='275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [275/275 00:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.03707250580191612,\n",
       " 'eval_accuracy': 0.9936247723132969,\n",
       " 'eval_runtime': 41.3827,\n",
       " 'eval_samples_per_second': 106.131,\n",
       " 'eval_steps_per_second': 6.645,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe98c748",
   "metadata": {},
   "source": [
    "### Checking its performance with a sample title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4863589a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:56:17.132890Z",
     "iopub.status.busy": "2023-07-12T14:56:17.132211Z",
     "iopub.status.idle": "2023-07-12T14:56:18.850110Z",
     "shell.execute_reply": "2023-07-12T14:56:18.848987Z",
     "shell.execute_reply.started": "2023-07-12T14:56:17.132852Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'SAVE EMAIL', 'score': 0.9475719332695007},\n",
       " {'label': 'PHISHING EMAIL', 'score': 0.05242803692817688}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a classification pipeline\n",
    "pipe = pipeline(\"text-classification\", output_dir, tokenizer=BERT_MODEL)\n",
    "sample_title = '''Why do employees leave companies — analysis of IBM employee data'''\n",
    "pipe(sample_title, top_k=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f5b152d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:56:18.852129Z",
     "iopub.status.busy": "2023-07-12T14:56:18.851728Z",
     "iopub.status.idle": "2023-07-12T14:56:18.934247Z",
     "shell.execute_reply": "2023-07-12T14:56:18.933121Z",
     "shell.execute_reply.started": "2023-07-12T14:56:18.852094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'PHISHING EMAIL', 'score': 0.9951817393302917},\n",
       " {'label': 'SAVE EMAIL', 'score': 0.00481817964464426}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the upper cased version\n",
    "sample_title2 = sample_title.upper()\n",
    "pipe(sample_title2, top_k=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8f9da51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:56:18.936339Z",
     "iopub.status.busy": "2023-07-12T14:56:18.935923Z",
     "iopub.status.idle": "2023-07-12T14:56:18.999913Z",
     "shell.execute_reply": "2023-07-12T14:56:18.998921Z",
     "shell.execute_reply.started": "2023-07-12T14:56:18.936303Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'SAVE EMAIL', 'score': 0.606553852558136},\n",
       " {'label': 'PHISHING EMAIL', 'score': 0.3934462070465088}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# more refined version\n",
    "sample_title3 = '''Why do employees leave companies?'''\n",
    "pipe(sample_title3, top_k=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84839853",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:56:36.046644Z",
     "iopub.status.busy": "2023-07-12T14:56:36.045602Z",
     "iopub.status.idle": "2023-07-12T14:56:36.071654Z",
     "shell.execute_reply": "2023-07-12T14:56:36.070615Z",
     "shell.execute_reply.started": "2023-07-12T14:56:36.046598Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14794f58e54a469da3b450b927cf9d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# finally, save the model to Huggingface\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6575154f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:56:43.329273Z",
     "iopub.status.busy": "2023-07-12T14:56:43.328838Z",
     "iopub.status.idle": "2023-07-12T14:56:43.570788Z",
     "shell.execute_reply": "2023-07-12T14:56:43.569798Z",
     "shell.execute_reply.started": "2023-07-12T14:56:43.329221Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RepoUrl('https://huggingface.co/dima806/phishing-email-detection', endpoint='https://huggingface.co', repo_type='model', repo_id='dima806/phishing-email-detection')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import create_repo\n",
    "create_repo(\"dima806/phishing-email-detection\", repo_type=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7790c991",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T14:56:48.056199Z",
     "iopub.status.busy": "2023-07-12T14:56:48.055394Z",
     "iopub.status.idle": "2023-07-12T14:57:21.511129Z",
     "shell.execute_reply": "2023-07-12T14:57:21.510005Z",
     "shell.execute_reply.started": "2023-07-12T14:56:48.056160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30521f7de8694f0992e67cdd28d2efaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/263M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89aa6b7d8ce143e589ff9710887e86bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler.pt:   0%|          | 0.00/627 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4230887594aa447dae5e2ca74adee768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "optimizer.pt:   0%|          | 0.00/526M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f73cde0a28a48718747782f03764a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 17 LFS files:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f621cd1da7f547bf972f5adde13af4d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rng_state.pth:   0%|          | 0.00/14.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e58cad382e284c97a36823fdc39eba9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/3.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2aa5737dbf4aeea919663fcf58121b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "optimizer.pt:   0%|          | 0.00/526M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fbfd5b5eef54a2d999cfc726e8704c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/263M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4f3b1fabde4783a5116e1410ef5792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rng_state.pth:   0%|          | 0.00/14.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25f08bbb2424bc9b9f6131eddd8ccfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler.pt:   0%|          | 0.00/627 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81187456b47458f95f8434f2d2f3694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/3.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a45210445e54fabba93d56d7f55ad8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "optimizer.pt:   0%|          | 0.00/526M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18782d0e9cc84a2b9355d337bc17f7fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/263M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576b76e6c2fa40fd8637d3932b45b0f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rng_state.pth:   0%|          | 0.00/14.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d78a87dfd44af08ab8e35e5b1c2676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler.pt:   0%|          | 0.00/627 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9083b52cd78a4534b6e0eb6b092edce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/3.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5985949544f64b05b5af7a94806b3047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/263M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a41a4a9ba7e4ecc9bf9de4bcac2729f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/3.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/dima806/phishing-email-detection/tree/main/.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "api.upload_folder(\n",
    "    folder_path=output_dir,\n",
    "    path_in_repo = \".\",\n",
    "    repo_id=\"dima806/phishing-email-detection\",\n",
    "    repo_type=\"model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04448c74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c289e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "064ab8b5",
   "metadata": {
    "papermill": {
     "duration": 0.011442,
     "end_time": "2023-08-13T15:41:41.890822",
     "exception": false,
     "start_time": "2023-08-13T15:41:41.879380",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Phishing Detection Using RoBERTa Large\n",
    "\"roberta-large\"<br/>\n",
    "https://huggingface.co/roberta-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f05b38cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T15:41:41.959817Z",
     "iopub.status.busy": "2023-08-13T15:41:41.959281Z",
     "iopub.status.idle": "2023-08-13T15:41:54.094410Z",
     "shell.execute_reply": "2023-08-13T15:41:54.093124Z"
    },
    "papermill": {
     "duration": 12.149727,
     "end_time": "2023-08-13T15:41:54.096910",
     "exception": false,
     "start_time": "2023-08-13T15:41:41.947183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chardet\r\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: chardet\r\n",
      "Successfully installed chardet-5.2.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39708b19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T15:41:54.121504Z",
     "iopub.status.busy": "2023-08-13T15:41:54.121184Z",
     "iopub.status.idle": "2023-08-13T15:41:54.126691Z",
     "shell.execute_reply": "2023-08-13T15:41:54.125842Z"
    },
    "papermill": {
     "duration": 0.019988,
     "end_time": "2023-08-13T15:41:54.128592",
     "exception": false,
     "start_time": "2023-08-13T15:41:54.108604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "debug = False\n",
    "debug2 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d10f3ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T15:41:54.153091Z",
     "iopub.status.busy": "2023-08-13T15:41:54.152322Z",
     "iopub.status.idle": "2023-08-13T15:41:59.765585Z",
     "shell.execute_reply": "2023-08-13T15:41:59.764916Z"
    },
    "papermill": {
     "duration": 5.627286,
     "end_time": "2023-08-13T15:41:59.767594",
     "exception": false,
     "start_time": "2023-08-13T15:41:54.140308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "import transformers\n",
    "import random\n",
    "import chardet\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "scaler = torch.cuda.amp.GradScaler() \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbc5d6b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T15:41:59.793163Z",
     "iopub.status.busy": "2023-08-13T15:41:59.792639Z",
     "iopub.status.idle": "2023-08-13T15:41:59.802591Z",
     "shell.execute_reply": "2023-08-13T15:41:59.801776Z"
    },
    "papermill": {
     "duration": 0.025293,
     "end_time": "2023-08-13T15:41:59.804674",
     "exception": false,
     "start_time": "2023-08-13T15:41:59.779381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_seed(SEED):\n",
    "    \n",
    "    random.seed(SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "SEED = 508\n",
    "random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35645220",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T15:41:59.828517Z",
     "iopub.status.busy": "2023-08-13T15:41:59.828252Z",
     "iopub.status.idle": "2023-08-13T15:45:43.109562Z",
     "shell.execute_reply": "2023-08-13T15:45:43.105020Z"
    },
    "papermill": {
     "duration": 223.304482,
     "end_time": "2023-08-13T15:45:43.120547",
     "exception": false,
     "start_time": "2023-08-13T15:41:59.816065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MacRoman\n"
     ]
    }
   ],
   "source": [
    "with open('C:/Users/CSNAP/Downloads/Final Project_ECE 8110/Phishing_Email.csv', 'rb') as f:\n",
    "    result = chardet.detect(f.read())\n",
    "print(result['encoding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2599364f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T15:45:43.144845Z",
     "iopub.status.busy": "2023-08-13T15:45:43.144532Z",
     "iopub.status.idle": "2023-08-13T15:45:43.820782Z",
     "shell.execute_reply": "2023-08-13T15:45:43.819681Z"
    },
    "papermill": {
     "duration": 0.691113,
     "end_time": "2023-08-13T15:45:43.823262",
     "exception": false,
     "start_time": "2023-08-13T15:45:43.132149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email Text</th>\n",
       "      <th>Email Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>re : 6 . 1100 , disc : uniformitarianism , re ...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the other side of * galicismos * * galicismo *...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>re : equistar deal tickets are you still avail...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nHello I am your hot lil horny toy.\\n    I am...</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>software at incredibly low prices ( 86 % lower...</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18645</th>\n",
       "      <td>date a lonely housewife always wanted to date ...</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18646</th>\n",
       "      <td>request submitted : access request for anita ....</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18647</th>\n",
       "      <td>re : important - prc mtg hi dorn &amp; john , as y...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18648</th>\n",
       "      <td>press clippings - letter on californian utilit...</td>\n",
       "      <td>Safe Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18649</th>\n",
       "      <td>empty</td>\n",
       "      <td>Phishing Email</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18634 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Email Text      Email Type\n",
       "0      re : 6 . 1100 , disc : uniformitarianism , re ...      Safe Email\n",
       "1      the other side of * galicismos * * galicismo *...      Safe Email\n",
       "2      re : equistar deal tickets are you still avail...      Safe Email\n",
       "3      \\nHello I am your hot lil horny toy.\\n    I am...  Phishing Email\n",
       "4      software at incredibly low prices ( 86 % lower...  Phishing Email\n",
       "...                                                  ...             ...\n",
       "18645  date a lonely housewife always wanted to date ...  Phishing Email\n",
       "18646  request submitted : access request for anita ....      Safe Email\n",
       "18647  re : important - prc mtg hi dorn & john , as y...      Safe Email\n",
       "18648  press clippings - letter on californian utilit...      Safe Email\n",
       "18649                                              empty  Phishing Email\n",
       "\n",
       "[18634 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Phishing Email', 'Safe Email']\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('C:/Users/CSNAP/Downloads/Final Project_ECE 8110/Phishing_Email.csv', \n",
    "                 encoding=result['encoding'])\n",
    "data=data[['Email Text','Email Type']]\n",
    "data=data.dropna()\n",
    "display(data)\n",
    "data.columns=['text','label']\n",
    "class_names=sorted(data['label'].unique().tolist())\n",
    "print(class_names)\n",
    "N=list(range(len(class_names)))\n",
    "normal_mapping=dict(zip(class_names,N)) \n",
    "reverse_mapping=dict(zip(N,class_names))       \n",
    "data['label']=data['label'].map(normal_mapping)\n",
    "n=len(data)\n",
    "M=list(range(n))\n",
    "random.seed(2023)\n",
    "random.shuffle(M)\n",
    "data=data.iloc[M]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b129c0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T15:45:43.848725Z",
     "iopub.status.busy": "2023-08-13T15:45:43.848133Z",
     "iopub.status.idle": "2023-08-13T15:45:43.855098Z",
     "shell.execute_reply": "2023-08-13T15:45:43.854256Z"
    },
    "papermill": {
     "duration": 0.021781,
     "end_time": "2023-08-13T15:45:43.857126",
     "exception": false,
     "start_time": "2023-08-13T15:45:43.835345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data[0:5000], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f45be8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T15:45:43.881846Z",
     "iopub.status.busy": "2023-08-13T15:45:43.881576Z",
     "iopub.status.idle": "2023-08-13T15:45:46.390689Z",
     "shell.execute_reply": "2023-08-13T15:45:46.389739Z"
    },
    "papermill": {
     "duration": 2.524056,
     "end_time": "2023-08-13T15:45:46.393230",
     "exception": false,
     "start_time": "2023-08-13T15:45:43.869174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2086395fd8b3483eb8ae6b00cbfec533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077c5c12a66c4a16972b78eb54463934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132891abad2f463d8e6707807b967e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tokenizer = transformers.BertTokenizer.from_pretrained(\"../input/bert-base-uncased\")\n",
    "#tokenizer = transformers.RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "tokenizer = transformers.RobertaTokenizer.from_pretrained(\"roberta-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24db5d85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T15:45:46.420581Z",
     "iopub.status.busy": "2023-08-13T15:45:46.419779Z",
     "iopub.status.idle": "2023-08-13T15:45:52.833703Z",
     "shell.execute_reply": "2023-08-13T15:45:52.832776Z"
    },
    "papermill": {
     "duration": 6.429729,
     "end_time": "2023-08-13T15:45:52.835979",
     "exception": false,
     "start_time": "2023-08-13T15:45:46.406250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> A man endowed with a 7-8\" hammer is simply\\n better equipped than a man with a 5-6\"hammer. \\nWould you rather havemore than enough to get the job done or fall short. It\\'s totally upto you. Our Methods are guaranteed to increase your size by 1-3\" Come in here and see how--DeathToSpamDeathToSpamDeathToSpam--\\n-------------------------------------------------------\\nThis sf.net email is sponsored by:ThinkGeek\\nWelcome to geek heaven.\\nhttp://thinkgeek.com/sf\\n_______________________________________________\\nSpamassassin-Sightings mailing list\\nSpamassassin-Sightings@lists.sourceforge.net\\nhttps://lists.sourceforge.net/lists/listinfo/spamassassin-sightings\\n</s>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_s = train['text'].iloc[0]\n",
    "result1 = tokenizer.encode_plus(test_s)\n",
    "tokenizer.decode(result1[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5367e673",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T15:45:52.862650Z",
     "iopub.status.busy": "2023-08-13T15:45:52.862350Z",
     "iopub.status.idle": "2023-08-13T15:45:52.868053Z",
     "shell.execute_reply": "2023-08-13T15:45:52.867200Z"
    },
    "papermill": {
     "duration": 0.021106,
     "end_time": "2023-08-13T15:45:52.870106",
     "exception": false,
     "start_time": "2023-08-13T15:45:52.849000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_s.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49b42849",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T15:45:52.896793Z",
     "iopub.status.busy": "2023-08-13T15:45:52.896516Z",
     "iopub.status.idle": "2023-08-13T15:45:52.903040Z",
     "shell.execute_reply": "2023-08-13T15:45:52.902198Z"
    },
    "papermill": {
     "duration": 0.021797,
     "end_time": "2023-08-13T15:45:52.905060",
     "exception": false,
     "start_time": "2023-08-13T15:45:52.883263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result2 = tokenizer.encode_plus(\n",
    "    test_s,\n",
    "    add_special_tokens = True, \n",
    "    max_length = 32, \n",
    "    pad_to_max_length = True, \n",
    "    truncation = True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df89801c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T15:45:52.930999Z",
     "iopub.status.busy": "2023-08-13T15:45:52.930718Z",
     "iopub.status.idle": "2023-08-13T15:45:52.936468Z",
     "shell.execute_reply": "2023-08-13T15:45:52.935607Z"
    },
    "papermill": {
     "duration": 0.020923,
     "end_time": "2023-08-13T15:45:52.938399",
     "exception": false,
     "start_time": "2023-08-13T15:45:52.917476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> A man endowed with a 7-8\" hammer is simply\\n better equipped than a man with a 5-6\"hammer. \\nWould you</s>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(result2[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "235eb674",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T15:45:52.964529Z",
     "iopub.status.busy": "2023-08-13T15:45:52.964252Z",
     "iopub.status.idle": "2023-08-13T15:45:52.975115Z",
     "shell.execute_reply": "2023-08-13T15:45:52.974264Z"
    },
    "papermill": {
     "duration": 0.026169,
     "end_time": "2023-08-13T15:45:52.977023",
     "exception": false,
     "start_time": "2023-08-13T15:45:52.950854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_sens = 32\n",
    "\n",
    "train = train.sort_values(\"label\").reset_index(drop=True)\n",
    "\n",
    "train[\"kfold\"] = train.index % 5\n",
    "\n",
    "p_train = train[train[\"kfold\"]!=0].reset_index(drop=True)\n",
    "p_valid = train[train[\"kfold\"]==0].reset_index(drop=True)\n",
    "\n",
    "p_test=test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecfc878",
   "metadata": {
    "papermill": {
     "duration": 0.012458,
     "end_time": "2023-08-13T15:45:53.002006",
     "exception": false,
     "start_time": "2023-08-13T15:45:52.989548",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "'token_type_ids' no need in RoBERTa/DeBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee24888e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T15:45:53.029174Z",
     "iopub.status.busy": "2023-08-13T15:45:53.028275Z",
     "iopub.status.idle": "2023-08-13T15:45:53.037392Z",
     "shell.execute_reply": "2023-08-13T15:45:53.036522Z"
    },
    "papermill": {
     "duration": 0.024552,
     "end_time": "2023-08-13T15:45:53.039357",
     "exception": false,
     "start_time": "2023-08-13T15:45:53.014805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BERTDataSet(Dataset):\n",
    "    \n",
    "    def __init__(self,sentences,targets):        \n",
    "        self.sentences = sentences\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):        \n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self,idx):        \n",
    "        sentence = self.sentences[idx]    \n",
    "        bert_sens = tokenizer.encode_plus(\n",
    "                                sentence,\n",
    "                                add_special_tokens = True, \n",
    "                                max_length = max_sens, \n",
    "                                pad_to_max_length = True, \n",
    "                                return_attention_mask = True)\n",
    "\n",
    "        ids = torch.tensor(bert_sens['input_ids'], dtype=torch.long)\n",
    "        mask = torch.tensor(bert_sens['attention_mask'], dtype=torch.long)\n",
    "\n",
    "        target = torch.tensor(self.targets[idx],dtype=torch.float)\n",
    "        \n",
    "        return {\n",
    "                'ids': ids,\n",
    "                'mask': mask,\n",
    "                'targets': target\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca7411ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T15:45:53.069567Z",
     "iopub.status.busy": "2023-08-13T15:45:53.069292Z",
     "iopub.status.idle": "2023-08-13T15:45:53.076166Z",
     "shell.execute_reply": "2023-08-13T15:45:53.075249Z"
    },
    "papermill": {
     "duration": 0.026255,
     "end_time": "2023-08-13T15:45:53.078142",
     "exception": false,
     "start_time": "2023-08-13T15:45:53.051887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = BERTDataSet(p_train[\"text\"],p_train[\"label\"])\n",
    "valid_dataset = BERTDataSet(p_valid[\"text\"],p_valid[\"label\"])\n",
    "test_dataset = BERTDataSet(p_test[\"text\"],p_test[\"label\"])\n",
    "\n",
    "train_batch = 16\n",
    "valid_batch = 32\n",
    "test_batch = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=train_batch,shuffle = True,num_workers=8,pin_memory=True)\n",
    "valid_dataloader = DataLoader(valid_dataset,batch_size=valid_batch,shuffle = False,num_workers=8,pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=test_batch,shuffle = False,num_workers=8,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a98495b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T15:45:53.104863Z",
     "iopub.status.busy": "2023-08-13T15:45:53.104108Z",
     "iopub.status.idle": "2023-08-13T15:46:03.434714Z",
     "shell.execute_reply": "2023-08-13T15:46:03.433717Z"
    },
    "papermill": {
     "duration": 10.346295,
     "end_time": "2023-08-13T15:46:03.437017",
     "exception": false,
     "start_time": "2023-08-13T15:45:53.090722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ba4512b5eb4f81bf3da765047cc5c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = transformers.RobertaForSequenceClassification.from_pretrained(\"roberta-large\",num_labels=1)\n",
    "#model = transformers.BertForSequenceClassification.from_pretrained(\"../input/bert-base-uncased\",num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "386bffcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T15:46:03.465991Z",
     "iopub.status.busy": "2023-08-13T15:46:03.465098Z",
     "iopub.status.idle": "2023-08-13T15:46:09.260792Z",
     "shell.execute_reply": "2023-08-13T15:46:09.259812Z"
    },
    "papermill": {
     "duration": 5.812549,
     "end_time": "2023-08-13T15:46:09.263026",
     "exception": false,
     "start_time": "2023-08-13T15:46:03.450477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44e5c40f",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-08-13T15:46:09.290903Z",
     "iopub.status.busy": "2023-08-13T15:46:09.290600Z",
     "iopub.status.idle": "2023-08-13T15:46:12.898017Z",
     "shell.execute_reply": "2023-08-13T15:46:12.896727Z"
    },
    "papermill": {
     "duration": 3.624172,
     "end_time": "2023-08-13T15:46:12.900529",
     "exception": false,
     "start_time": "2023-08-13T15:46:09.276357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "for a in train_dataloader:\n",
    "    ids = a[\"ids\"].to(device)\n",
    "    mask = a[\"mask\"].to(device)\n",
    "\n",
    "    output = model(ids,mask)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48676385",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T15:46:12.931129Z",
     "iopub.status.busy": "2023-08-13T15:46:12.930207Z",
     "iopub.status.idle": "2023-08-13T15:46:12.938633Z",
     "shell.execute_reply": "2023-08-13T15:46:12.937755Z"
    },
    "papermill": {
     "duration": 0.02571,
     "end_time": "2023-08-13T15:46:12.940792",
     "exception": false,
     "start_time": "2023-08-13T15:46:12.915082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = output[\"logits\"].squeeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1023ab50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T15:46:12.970302Z",
     "iopub.status.busy": "2023-08-13T15:46:12.969766Z",
     "iopub.status.idle": "2023-08-13T15:46:12.985537Z",
     "shell.execute_reply": "2023-08-13T15:46:12.984676Z"
    },
    "papermill": {
     "duration": 0.032478,
     "end_time": "2023-08-13T15:46:12.987475",
     "exception": false,
     "start_time": "2023-08-13T15:46:12.954997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "LR=2e-5\n",
    "optimizer = AdamW(model.parameters(), LR,betas=(0.9, 0.999), weight_decay=1e-2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1869b13",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-08-13T15:46:13.017268Z",
     "iopub.status.busy": "2023-08-13T15:46:13.016466Z",
     "iopub.status.idle": "2023-08-13T15:46:13.023255Z",
     "shell.execute_reply": "2023-08-13T15:46:13.022148Z"
    },
    "papermill": {
     "duration": 0.023823,
     "end_time": "2023-08-13T15:46:13.025172",
     "exception": false,
     "start_time": "2023-08-13T15:46:13.001349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "epochs = 20\n",
    "if debug:\n",
    "    epochs = 1\n",
    "train_steps = int(len(p_train)/train_batch*epochs)\n",
    "print(train_steps)\n",
    "num_steps = int(train_steps*0.1)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d6f010f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T15:46:13.055724Z",
     "iopub.status.busy": "2023-08-13T15:46:13.054230Z",
     "iopub.status.idle": "2023-08-13T15:46:13.059755Z",
     "shell.execute_reply": "2023-08-13T15:46:13.058919Z"
    },
    "papermill": {
     "duration": 0.02246,
     "end_time": "2023-08-13T15:46:13.061678",
     "exception": false,
     "start_time": "2023-08-13T15:46:13.039218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_fn(output,target):\n",
    "    return torch.sqrt(nn.MSELoss()(output,target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edfc776",
   "metadata": {
    "papermill": {
     "duration": 0.013716,
     "end_time": "2023-08-13T15:46:13.089209",
     "exception": false,
     "start_time": "2023-08-13T15:46:13.075493",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### def training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "259c876f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T15:46:13.118341Z",
     "iopub.status.busy": "2023-08-13T15:46:13.117550Z",
     "iopub.status.idle": "2023-08-13T15:46:13.127479Z",
     "shell.execute_reply": "2023-08-13T15:46:13.126496Z"
    },
    "papermill": {
     "duration": 0.026563,
     "end_time": "2023-08-13T15:46:13.129575",
     "exception": false,
     "start_time": "2023-08-13T15:46:13.103012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training(\n",
    "    train_dataloader,\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler\n",
    "):\n",
    "    \n",
    "    model.train()\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    allpreds = []\n",
    "    alltargets = []\n",
    "\n",
    "    for a in train_dataloader:\n",
    "\n",
    "        losses = []\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "\n",
    "            ids = a[\"ids\"].to(device,non_blocking=True)\n",
    "            mask = a[\"mask\"].to(device,non_blocking=True)\n",
    "\n",
    "            output = model(ids,mask)\n",
    "            output = output[\"logits\"].squeeze(-1)\n",
    "            target = a[\"targets\"].to(device,non_blocking=True)\n",
    "            loss = loss_fn(output,target)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            allpreds.append(output.detach().cpu().numpy())\n",
    "            alltargets.append(target.detach().squeeze(-1).cpu().numpy())\n",
    "\n",
    "        scaler.scale(loss).backward() \n",
    "        scaler.step(optimizer) \n",
    "        scaler.update() \n",
    "        \n",
    "        del loss \n",
    "\n",
    "        scheduler.step() \n",
    "\n",
    "    allpreds = np.concatenate(allpreds)\n",
    "    alltargets = np.concatenate(alltargets)\n",
    "    losses = np.mean(losses)\n",
    "    train_rme_loss = np.sqrt(mean_squared_error(alltargets,allpreds))\n",
    "\n",
    "    return losses,train_rme_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf0cd37",
   "metadata": {
    "papermill": {
     "duration": 0.013557,
     "end_time": "2023-08-13T15:46:13.157243",
     "exception": false,
     "start_time": "2023-08-13T15:46:13.143686",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### def validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "848ee523",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T15:46:13.189137Z",
     "iopub.status.busy": "2023-08-13T15:46:13.188418Z",
     "iopub.status.idle": "2023-08-13T15:46:13.197318Z",
     "shell.execute_reply": "2023-08-13T15:46:13.196473Z"
    },
    "papermill": {
     "duration": 0.026077,
     "end_time": "2023-08-13T15:46:13.199275",
     "exception": false,
     "start_time": "2023-08-13T15:46:13.173198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validating(valid_dataloader,model):\n",
    "    \n",
    "    model.eval()\n",
    "    allpreds = []\n",
    "    alltargets = []\n",
    "\n",
    "    for a in valid_dataloader:\n",
    "        losses = []\n",
    "        with torch.no_grad():\n",
    "\n",
    "            ids = a[\"ids\"].to(device)\n",
    "            mask = a[\"mask\"].to(device)\n",
    "\n",
    "            output = model(ids,mask)\n",
    "            output = output[\"logits\"].squeeze(-1)\n",
    "            target = a[\"targets\"].to(device)\n",
    "            loss = loss_fn(output,target)\n",
    "            losses.append(loss.item())\n",
    "            allpreds.append(output.detach().cpu().numpy())\n",
    "            alltargets.append(target.detach().squeeze(-1).cpu().numpy())\n",
    "            \n",
    "            del loss\n",
    "\n",
    "    allpreds = np.concatenate(allpreds)\n",
    "    alltargets = np.concatenate(alltargets)\n",
    "    losses = np.mean(losses)\n",
    "    valid_rme_loss = np.sqrt(mean_squared_error(alltargets,allpreds))\n",
    "\n",
    "    return allpreds,losses,valid_rme_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d639c4d",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-08-13T15:46:13.228385Z",
     "iopub.status.busy": "2023-08-13T15:46:13.227717Z",
     "iopub.status.idle": "2023-08-13T15:47:45.022353Z",
     "shell.execute_reply": "2023-08-13T15:47:45.020930Z"
    },
    "papermill": {
     "duration": 91.811884,
     "end_time": "2023-08-13T15:47:45.024872",
     "exception": false,
     "start_time": "2023-08-13T15:46:13.212988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "if debug2 == False:\n",
    "    for a in range(epochs):\n",
    "        for b in train_dataloader:\n",
    "            break\n",
    "\n",
    "    losses,train_rme_loss = training(train_dataloader,model,optimizer,scheduler)\n",
    "\n",
    "    for a in valid_dataloader:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736482b9",
   "metadata": {
    "papermill": {
     "duration": 0.026874,
     "end_time": "2023-08-13T15:47:45.079345",
     "exception": false,
     "start_time": "2023-08-13T15:47:45.052471",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training and Validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a02160d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T15:47:45.135835Z",
     "iopub.status.busy": "2023-08-13T15:47:45.135463Z",
     "iopub.status.idle": "2023-08-13T16:07:41.207059Z",
     "shell.execute_reply": "2023-08-13T16:07:41.205787Z"
    },
    "papermill": {
     "duration": 1196.102979,
     "end_time": "2023-08-13T16:07:41.209761",
     "exception": false,
     "start_time": "2023-08-13T15:47:45.106782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------0start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.28224143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "  5%|▌         | 1/20 [00:57<18:13, 57.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.26288044\n",
      "Save first model\n",
      "---------------1start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.22614333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.25666654\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [02:08<19:35, 65.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------2start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.2028507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.24499148\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [03:21<19:28, 68.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------3start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.18977372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 20%|██        | 4/20 [04:18<17:08, 64.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.24531391\n",
      "---------------4start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.19027989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.22878982\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [05:30<16:46, 67.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------5start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.16190927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 30%|███       | 6/20 [06:27<14:51, 63.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.24813439\n",
      "---------------6start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.16638978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.21786913\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [07:39<14:22, 66.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------7start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.1452719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 40%|████      | 8/20 [08:36<12:40, 63.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.23254845\n",
      "---------------8start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.13331835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 45%|████▌     | 9/20 [09:33<11:13, 61.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.25938952\n",
      "---------------9start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.15405649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 50%|█████     | 10/20 [10:29<09:58, 59.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.25866893\n",
      "---------------10start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.13998716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 55%|█████▌    | 11/20 [11:26<08:48, 58.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.25629666\n",
      "---------------11start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.13806471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 60%|██████    | 12/20 [12:22<07:44, 58.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.23864579\n",
      "---------------12start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.15017906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 65%|██████▌   | 13/20 [13:19<06:44, 57.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.23406316\n",
      "---------------13start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.13597773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 70%|███████   | 14/20 [14:16<05:45, 57.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.25939927\n",
      "---------------14start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.1250548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 75%|███████▌  | 15/20 [15:13<04:46, 57.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.25410804\n",
      "---------------15start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.12518992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 80%|████████  | 16/20 [16:10<03:48, 57.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.25013503\n",
      "---------------16start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.12510727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 85%|████████▌ | 17/20 [17:06<02:50, 56.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.26272604\n",
      "---------------17start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.12856428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 90%|█████████ | 18/20 [18:02<01:53, 56.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.25587675\n",
      "---------------18start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.12304388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 95%|█████████▌| 19/20 [18:59<00:56, 56.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.2580818\n",
      "---------------19start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.121087156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|██████████| 20/20 [19:56<00:00, 59.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.2580818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainlosses = []\n",
    "vallosses = []\n",
    "bestscore = None\n",
    "trainscores = []\n",
    "validscores = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    \n",
    "    print(\"---------------\" + str(epoch) + \"start-------------\")\n",
    "    \n",
    "    trainloss,trainscore = training(train_dataloader,model,optimizer,scheduler)    \n",
    "    trainlosses.append(trainloss)\n",
    "    trainscores.append(trainscore)\n",
    "    \n",
    "    print(\"trainscore is \" + str(trainscore))\n",
    "    \n",
    "    preds,validloss,valscore=validating(valid_dataloader,model)    \n",
    "    vallosses.append(validloss)\n",
    "    validscores.append(valscore)\n",
    "    \n",
    "    print(\"valscore is \" + str(valscore))\n",
    "    \n",
    "    if bestscore is None:\n",
    "        bestscore = valscore\n",
    "        \n",
    "        print(\"Save first model\")\n",
    "        \n",
    "        state = {\n",
    "                        'state_dict': model.state_dict(),\n",
    "                        'optimizer_dict': optimizer.state_dict(),\n",
    "                        \"bestscore\":bestscore\n",
    "                    }\n",
    "            \n",
    "        #torch.save(state, \"model0.pth\")\n",
    "        \n",
    "    elif bestscore > valscore:\n",
    "        \n",
    "        bestscore = valscore        \n",
    "        print(\"found better point\")        \n",
    "        state = {\n",
    "                        'state_dict': model.state_dict(),\n",
    "                        'optimizer_dict': optimizer.state_dict(),\n",
    "                        \"bestscore\":bestscore\n",
    "                    }\n",
    "            \n",
    "        torch.save(state, \"model.pth\")\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a95dcad9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T16:07:41.323276Z",
     "iopub.status.busy": "2023-08-13T16:07:41.322921Z",
     "iopub.status.idle": "2023-08-13T16:07:42.173876Z",
     "shell.execute_reply": "2023-08-13T16:07:42.172859Z"
    },
    "papermill": {
     "duration": 0.910143,
     "end_time": "2023-08-13T16:07:42.176007",
     "exception": false,
     "start_time": "2023-08-13T16:07:41.265864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(p_valid['label'],preds, alpha=0.2)\n",
    "plt.title('Validation Prediction Result')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Prediction')\n",
    "plt.show()\n",
    "\n",
    "x = np.arange(epochs)\n",
    "plt.title('Validation Losses')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(x,trainlosses)\n",
    "plt.plot(x,vallosses)\n",
    "plt.show()\n",
    "\n",
    "x = np.arange(epochs)\n",
    "plt.title('Validation Scores')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Score')\n",
    "plt.plot(x,trainscores)\n",
    "plt.plot(x,validscores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb62e2b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T16:07:42.293214Z",
     "iopub.status.busy": "2023-08-13T16:07:42.292276Z",
     "iopub.status.idle": "2023-08-13T16:07:42.311144Z",
     "shell.execute_reply": "2023-08-13T16:07:42.310233Z"
    },
    "papermill": {
     "duration": 0.078996,
     "end_time": "2023-08-13T16:07:42.313103",
     "exception": false,
     "start_time": "2023-08-13T16:07:42.234107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "Phishing Email     0.9097    0.9125    0.9111       320\n",
      "    Safe Email     0.9415    0.9396    0.9406       480\n",
      "\n",
      "      accuracy                         0.9287       800\n",
      "     macro avg     0.9256    0.9260    0.9258       800\n",
      "  weighted avg     0.9288    0.9287    0.9288       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_true = p_valid['label']\n",
    "val_pred = []\n",
    "for p in preds:\n",
    "    val_pred+=[round(p,0)]\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(val_true,val_pred,target_names=class_names,digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59572e5",
   "metadata": {
    "papermill": {
     "duration": 0.057386,
     "end_time": "2023-08-13T16:07:42.428892",
     "exception": false,
     "start_time": "2023-08-13T16:07:42.371506",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5169bc47",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-08-13T16:07:42.545969Z",
     "iopub.status.busy": "2023-08-13T16:07:42.545639Z",
     "iopub.status.idle": "2023-08-13T17:27:12.336296Z",
     "shell.execute_reply": "2023-08-13T17:27:12.333610Z"
    },
    "papermill": {
     "duration": 4769.850912,
     "end_time": "2023-08-13T17:27:12.338455",
     "exception": false,
     "start_time": "2023-08-13T16:07:42.487543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------0start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.50681156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.2741064\n",
      "Save first model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [01:09<22:07, 69.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------1start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.28984907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.21825817\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [02:20<21:01, 70.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------2start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.4035427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 15%|█▌        | 3/20 [03:15<17:53, 63.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.5167167\n",
      "---------------3start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.5114539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 20%|██        | 4/20 [04:09<15:54, 59.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.49007025\n",
      "---------------4start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.50635344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 25%|██▌       | 5/20 [05:04<14:28, 57.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.4902506\n",
      "---------------5start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.50654733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 30%|███       | 6/20 [05:58<13:14, 56.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.52477926\n",
      "---------------6start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.5066831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 35%|███▌      | 7/20 [06:53<12:10, 56.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.49227595\n",
      "---------------7start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.50704914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 40%|████      | 8/20 [07:48<11:07, 55.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.49195918\n",
      "---------------8start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.50067717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 45%|████▌     | 9/20 [08:42<10:08, 55.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.49019116\n",
      "---------------9start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.5090815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 50%|█████     | 10/20 [09:37<09:10, 55.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.48998126\n",
      "---------------10start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.5054205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 55%|█████▌    | 11/20 [10:31<08:12, 54.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.49131593\n",
      "---------------11start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.5038265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 60%|██████    | 12/20 [11:25<07:17, 54.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.4956698\n",
      "---------------12start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.50224894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 65%|██████▌   | 13/20 [12:19<06:21, 54.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.49211442\n",
      "---------------13start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.5039268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 70%|███████   | 14/20 [13:14<05:27, 54.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.4900585\n",
      "---------------14start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.50657123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 75%|███████▌  | 15/20 [14:08<04:32, 54.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.4905249\n",
      "---------------15start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.5017962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 80%|████████  | 16/20 [15:03<03:37, 54.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.4900989\n",
      "---------------16start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.49839628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 85%|████████▌ | 17/20 [15:58<02:43, 54.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.49341443\n",
      "---------------17start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.49744967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 90%|█████████ | 18/20 [16:52<01:49, 54.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.49507004\n",
      "---------------18start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.50028217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 95%|█████████▌| 19/20 [17:47<00:54, 54.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.49046755\n",
      "---------------19start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.49997565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|██████████| 20/20 [18:41<00:00, 56.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.49072003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------0start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.4747625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.28789008\n",
      "Save first model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [01:09<22:08, 69.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------1start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.29577908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.19417936\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [02:20<21:08, 70.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------2start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.2451103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 15%|█▌        | 3/20 [03:15<17:57, 63.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.22661057\n",
      "---------------3start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.22236428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 20%|██        | 4/20 [04:10<16:00, 60.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.2512133\n",
      "---------------4start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.19747725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.1751534\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [05:21<15:57, 63.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------5start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.1735614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 30%|███       | 6/20 [06:16<14:12, 60.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.200662\n",
      "---------------6start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.16297555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 35%|███▌      | 7/20 [07:11<12:48, 59.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.20145066\n",
      "---------------7start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.1653543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 40%|████      | 8/20 [08:06<11:32, 57.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.18891977\n",
      "---------------8start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.15744577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 45%|████▌     | 9/20 [09:01<10:24, 56.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.2843663\n",
      "---------------9start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.1536597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 50%|█████     | 10/20 [09:55<09:21, 56.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.20917757\n",
      "---------------10start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.16010587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 55%|█████▌    | 11/20 [10:50<08:21, 55.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.181196\n",
      "---------------11start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.143809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 60%|██████    | 12/20 [11:45<07:23, 55.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.17957395\n",
      "---------------12start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.1382885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 65%|██████▌   | 13/20 [12:40<06:27, 55.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.183547\n",
      "---------------13start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.1392432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 70%|███████   | 14/20 [13:35<05:31, 55.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.21066275\n",
      "---------------14start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.13262907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 75%|███████▌  | 15/20 [14:30<04:35, 55.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.18086241\n",
      "---------------15start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.12925166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 80%|████████  | 16/20 [15:25<03:40, 55.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.18249798\n",
      "---------------16start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.1304085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 85%|████████▌ | 17/20 [16:20<02:45, 55.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.17848523\n",
      "---------------17start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.12863708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 90%|█████████ | 18/20 [17:15<01:49, 54.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.17895274\n",
      "---------------18start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.12542449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 95%|█████████▌| 19/20 [18:11<00:55, 55.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.17991355\n",
      "---------------19start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.12323404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|██████████| 20/20 [19:05<00:00, 57.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.18276007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------0start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.46664202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.2856018\n",
      "Save first model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [01:10<22:14, 70.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------1start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.27631485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.25964808\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [02:20<21:06, 70.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------2start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.24980001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.21424043\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [03:30<19:51, 70.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------3start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.21428892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 20%|██        | 4/20 [04:26<17:13, 64.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.22069548\n",
      "---------------4start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.2064081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.20475493\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [05:36<16:36, 66.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------5start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.18151847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.20455009\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [06:46<15:49, 67.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------6start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.18531565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 35%|███▌      | 7/20 [07:41<13:46, 63.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.20650434\n",
      "---------------7start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.16905628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.200565\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [08:51<13:08, 65.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------8start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.15980974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.19281547\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [10:02<12:19, 67.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------9start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.15256944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 50%|█████     | 10/20 [10:57<10:35, 63.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.19331157\n",
      "---------------10start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.1509347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 55%|█████▌    | 11/20 [11:52<09:08, 60.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.19706687\n",
      "---------------11start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.14484209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.18244314\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [13:04<08:34, 64.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------12start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.16508847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 65%|██████▌   | 13/20 [14:00<07:11, 61.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.19937761\n",
      "---------------13start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.14244881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 70%|███████   | 14/20 [14:55<05:57, 59.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.19460519\n",
      "---------------14start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.13350488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.18195501\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [16:05<05:13, 62.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------15start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.13597429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.16619338\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [17:14<04:19, 64.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------16start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.12992696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.16048819\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [18:24<03:18, 66.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------17start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.12647524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 90%|█████████ | 18/20 [19:20<02:06, 63.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.16323386\n",
      "---------------18start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.12834361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 95%|█████████▌| 19/20 [20:14<01:00, 60.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.16174246\n",
      "---------------19start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.13054976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|██████████| 20/20 [21:09<00:00, 63.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.16129878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------0start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.45721564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.26095206\n",
      "Save first model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [01:10<22:13, 70.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------1start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.30451605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.2137666\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [02:20<21:06, 70.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------2start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.24138379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.20359716\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [03:30<19:55, 70.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------3start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.21190201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.19266681\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [04:41<18:47, 70.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------4start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.20091575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 25%|██▌       | 5/20 [05:36<16:14, 64.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.22551818\n",
      "---------------5start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.18355514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.17087306\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [06:47<15:38, 67.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------6start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.17637342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 35%|███▌      | 7/20 [07:43<13:42, 63.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.17677203\n",
      "---------------7start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.18041891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 40%|████      | 8/20 [08:38<12:09, 60.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.22309594\n",
      "---------------8start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.16966537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 45%|████▌     | 9/20 [09:34<10:49, 59.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.19341505\n",
      "---------------9start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.15578505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 50%|█████     | 10/20 [10:29<09:38, 57.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.22090298\n",
      "---------------10start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.15401414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 55%|█████▌    | 11/20 [11:25<08:35, 57.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.18706697\n",
      "---------------11start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.14252183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 60%|██████    | 12/20 [12:20<07:34, 56.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.1885702\n",
      "---------------12start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.17987628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 65%|██████▌   | 13/20 [13:16<06:35, 56.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.18077192\n",
      "---------------13start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.14052062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 70%|███████   | 14/20 [14:11<05:36, 56.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.22481756\n",
      "---------------14start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.13674456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 75%|███████▌  | 15/20 [15:07<04:39, 55.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.18569456\n",
      "---------------15start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.13346486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 80%|████████  | 16/20 [16:02<03:42, 55.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.19083358\n",
      "---------------16start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.13018236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 85%|████████▌ | 17/20 [16:58<02:47, 55.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.18700159\n",
      "---------------17start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.12938978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 90%|█████████ | 18/20 [17:53<01:51, 55.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.1849071\n",
      "---------------18start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.12816337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 95%|█████████▌| 19/20 [18:48<00:55, 55.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.18808933\n",
      "---------------19start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.1281689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|██████████| 20/20 [19:44<00:00, 59.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.18550648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bestscores = []\n",
    "bestscores.append(bestscore)\n",
    "\n",
    "for fold in range(1,5):\n",
    "    \n",
    "    # initializing the data\n",
    "    p_train = train[train[\"kfold\"]!=fold].reset_index(drop=True)\n",
    "    p_valid = train[train[\"kfold\"]==fold].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = BERTDataSet(p_train[\"text\"],p_train[\"label\"])\n",
    "    valid_dataset = BERTDataSet(p_valid[\"text\"],p_valid[\"label\"])\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset,batch_size=train_batch,shuffle = True,num_workers=4,pin_memory=True)\n",
    "    valid_dataloader = DataLoader(valid_dataset,batch_size=valid_batch,shuffle = False,num_workers=4,pin_memory=True)\n",
    "\n",
    "    model = transformers.RobertaForSequenceClassification.from_pretrained(\"roberta-large\",num_labels=1)\n",
    "\n",
    "    model.to(device)\n",
    "    LR=2e-5\n",
    "    optimizer = AdamW(model.parameters(), LR,betas=(0.9, 0.999), weight_decay=1e-2) # AdamW optimizer\n",
    "    train_steps = int(len(p_train)/train_batch*epochs)\n",
    "    num_steps = int(train_steps*0.1)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)\n",
    "\n",
    "    trainlosses = []\n",
    "    vallosses = []\n",
    "    bestscore = None\n",
    "    trainscores = []\n",
    "    validscores = []\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "\n",
    "        print(\"---------------\" + str(epoch) + \"start-------------\")\n",
    "\n",
    "        trainloss,trainscore = training(train_dataloader,model,optimizer,scheduler)\n",
    "        trainlosses.append(trainloss)\n",
    "        trainscores.append(trainscore)\n",
    "\n",
    "        print(\"trainscore is \" + str(trainscore))\n",
    "\n",
    "        preds,validloss,valscore=validating(valid_dataloader,model)\n",
    "        vallosses.append(validloss)\n",
    "        validscores.append(valscore)\n",
    "\n",
    "        print(\"valscore is \" + str(valscore))\n",
    "\n",
    "        if bestscore is None:\n",
    "            bestscore = valscore\n",
    "\n",
    "            print(\"Save first model\")\n",
    "\n",
    "            state = {\n",
    "                            'state_dict': model.state_dict(),\n",
    "                            'optimizer_dict': optimizer.state_dict(),\n",
    "                            \"bestscore\":bestscore\n",
    "                        }\n",
    "\n",
    "            torch.save(state, \"model.pth\") #\" + str(fold) + \"\n",
    "\n",
    "        elif bestscore > valscore:\n",
    "            bestscore = valscore\n",
    "            print(\"found better point\")\n",
    "\n",
    "            state = {\n",
    "                            'state_dict': model.state_dict(),\n",
    "                            'optimizer_dict': optimizer.state_dict(),\n",
    "                            \"bestscore\":bestscore\n",
    "                        }\n",
    "            torch.save(state, \"model.pth\")#\"+ str(fold) + \"\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "    bestscores.append(bestscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf775523",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T17:27:12.605723Z",
     "iopub.status.busy": "2023-08-13T17:27:12.604614Z",
     "iopub.status.idle": "2023-08-13T17:27:12.612338Z",
     "shell.execute_reply": "2023-08-13T17:27:12.611352Z"
    },
    "papermill": {
     "duration": 0.143826,
     "end_time": "2023-08-13T17:27:12.614452",
     "exception": false,
     "start_time": "2023-08-13T17:27:12.470626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.21786913, 0.21825817, 0.1751534, 0.16048819, 0.17087306]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ce58b54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T17:27:12.872691Z",
     "iopub.status.busy": "2023-08-13T17:27:12.872349Z",
     "iopub.status.idle": "2023-08-13T17:27:12.877654Z",
     "shell.execute_reply": "2023-08-13T17:27:12.876708Z"
    },
    "papermill": {
     "duration": 0.137806,
     "end_time": "2023-08-13T17:27:12.879896",
     "exception": false,
     "start_time": "2023-08-13T17:27:12.742090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my cv is 0.18852839\n"
     ]
    }
   ],
   "source": [
    "np.mean(bestscores)\n",
    "print(\"my cv is \" + str(np.mean(bestscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6a758a",
   "metadata": {
    "papermill": {
     "duration": 0.129414,
     "end_time": "2023-08-13T17:27:13.138927",
     "exception": false,
     "start_time": "2023-08-13T17:27:13.009513",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Prediction\n",
    "not use saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6446db7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T17:27:13.402430Z",
     "iopub.status.busy": "2023-08-13T17:27:13.401785Z",
     "iopub.status.idle": "2023-08-13T17:27:13.409009Z",
     "shell.execute_reply": "2023-08-13T17:27:13.408116Z"
    },
    "papermill": {
     "duration": 0.139117,
     "end_time": "2023-08-13T17:27:13.410995",
     "exception": false,
     "start_time": "2023-08-13T17:27:13.271878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predicting(test_dataloader,model):\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()   \n",
    "    allpreds = []\n",
    "    preds = []\n",
    "    allvalloss=0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for a in test_dataloader:\n",
    "\n",
    "            ids = a[\"ids\"].to(device)\n",
    "            mask = a[\"mask\"].to(device)\n",
    "\n",
    "            output = model(ids,mask)\n",
    "            output = output[\"logits\"].squeeze(-1)\n",
    "            preds.append(output.cpu().numpy())\n",
    "\n",
    "        preds = np.concatenate(preds)\n",
    "        allpreds.append(preds)\n",
    "\n",
    "    return allpreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d4162e0",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-08-13T17:27:13.990749Z",
     "iopub.status.busy": "2023-08-13T17:27:13.990361Z",
     "iopub.status.idle": "2023-08-13T17:27:24.320757Z",
     "shell.execute_reply": "2023-08-13T17:27:24.319857Z"
    },
    "papermill": {
     "duration": 10.462198,
     "end_time": "2023-08-13T17:27:24.323055",
     "exception": false,
     "start_time": "2023-08-13T17:27:13.860857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#model initialized\n",
    "model = transformers.RobertaForSequenceClassification.from_pretrained(\"roberta-large\",num_labels=1)\n",
    "\n",
    "pthes = [os.path.join(\"./\",s) for s in os.listdir(\"./\") if \".pth\" in s]\n",
    "\n",
    "def predicting2(\n",
    "    test_dataloader,\n",
    "    model,\n",
    "    pthes \n",
    "):\n",
    "\n",
    "    allpreds = []    \n",
    "    for pth in pthes:\n",
    "        \n",
    "        state = torch.load(pth)        \n",
    "        model.load_state_dict(state[\"state_dict\"])\n",
    "        model.to(device)\n",
    "        model.eval()      \n",
    "        preds = []\n",
    "        allvalloss=0\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for a in test_dataloader:\n",
    "\n",
    "                ids = a[\"ids\"].to(device)\n",
    "                mask = a[\"mask\"].to(device)\n",
    "\n",
    "                output = model(ids,mask)\n",
    "                output = output[\"logits\"].squeeze(-1)\n",
    "                preds.append(output.cpu().numpy())\n",
    "\n",
    "            preds = np.concatenate(preds)           \n",
    "            allpreds.append(preds)\n",
    "\n",
    "    return allpreds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0103788",
   "metadata": {
    "papermill": {
     "duration": 0.12665,
     "end_time": "2023-08-13T17:27:24.576737",
     "exception": false,
     "start_time": "2023-08-13T17:27:24.450087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Predict the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9889012f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T17:27:24.849199Z",
     "iopub.status.busy": "2023-08-13T17:27:24.848329Z",
     "iopub.status.idle": "2023-08-13T17:27:52.821178Z",
     "shell.execute_reply": "2023-08-13T17:27:52.819841Z"
    },
    "papermill": {
     "duration": 28.113764,
     "end_time": "2023-08-13T17:27:52.824193",
     "exception": false,
     "start_time": "2023-08-13T17:27:24.710429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "#tpreds = predicting(test_dataloader,model)\n",
    "tpreds = predicting2(test_dataloader,model,pthes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dacb654d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-13T17:27:53.090471Z",
     "iopub.status.busy": "2023-08-13T17:27:53.090085Z",
     "iopub.status.idle": "2023-08-13T17:27:53.112250Z",
     "shell.execute_reply": "2023-08-13T17:27:53.110845Z"
    },
    "papermill": {
     "duration": 0.155878,
     "end_time": "2023-08-13T17:27:53.114698",
     "exception": false,
     "start_time": "2023-08-13T17:27:52.958820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "Phishing Email     0.9577    0.9073    0.9318       399\n",
      "    Safe Email     0.9405    0.9734    0.9567       601\n",
      "\n",
      "      accuracy                         0.9470      1000\n",
      "     macro avg     0.9491    0.9403    0.9442      1000\n",
      "  weighted avg     0.9474    0.9470    0.9467      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_true = p_test['label']\n",
    "test_pred = []\n",
    "for p in tpreds[0]:\n",
    "    test_pred+=[round(p,0)]\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_true,test_pred,target_names=class_names,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651ec551",
   "metadata": {
    "papermill": {
     "duration": 0.12925,
     "end_time": "2023-08-13T17:27:53.375737",
     "exception": false,
     "start_time": "2023-08-13T17:27:53.246487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6386.07584,
   "end_time": "2023-08-13T17:27:57.138784",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-13T15:41:31.062944",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "05b4dcc081a9431792cc04b2fc5c2f21": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "064bd7b025014d72a2993267a257471c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "074c9d3d29e645d388743b1943f24421": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "077c5c12a66c4a16972b78eb54463934": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_60873259ebc74ba1bd543e93c35ca382",
        "IPY_MODEL_0eb1e978484a475695790152de67bf65",
        "IPY_MODEL_5a3c3725428942b7aba3d886ac3f18df"
       ],
       "layout": "IPY_MODEL_d0274c111c2f48a581b031975e94c90b"
      }
     },
     "0eb1e978484a475695790152de67bf65": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_064bd7b025014d72a2993267a257471c",
       "max": 456318,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b020975771c04098aafa4133091426b0",
       "value": 456318
      }
     },
     "132891abad2f463d8e6707807b967e79": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c877632270234002b4bc965b7c9066a3",
        "IPY_MODEL_5c855a6379f24eab925c21fad6580df8",
        "IPY_MODEL_a734f3e3fc1f41ffa7e6df985fcf8519"
       ],
       "layout": "IPY_MODEL_f8e3dea30c724373a1c12565c4ad24e1"
      }
     },
     "159ed5f4e0e348b2984629d7b0b958ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "16dff806897f43ae9fb215e5a65bbb27": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_38e1697b0ff84a6eaf3a4c48e31d7e53",
       "max": 898823,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a58f9e8554dd497b9096cb0abba83b70",
       "value": 898823
      }
     },
     "17a51cedfeaa4ef4bf72da7748099364": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8593c9178b7c408ca02f4d4e18d11b09",
       "placeholder": "​",
       "style": "IPY_MODEL_4c4572808a8f4e4281b79995b23c611f",
       "value": " 1.42G/1.42G [00:03&lt;00:00, 406MB/s]"
      }
     },
     "1dea960f8dbd47748d36c15c2066dbd1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2086395fd8b3483eb8ae6b00cbfec533": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8748fc68f316443d9bb87545cf3fac30",
        "IPY_MODEL_16dff806897f43ae9fb215e5a65bbb27",
        "IPY_MODEL_9ba01c5cd4e34d24b6ef1329281d0b82"
       ],
       "layout": "IPY_MODEL_bc4c4afeecdf4b9d86b396474404cbba"
      }
     },
     "2c9bfbc6f34d4e53b2d2cc37fb2515ab": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "36982ad90e3a4b618f6efd3cae9108b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "36c74edf53f64d81bcc07b0e2b0fe444": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "38e1697b0ff84a6eaf3a4c48e31d7e53": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "46025fc4fd5f4fe89afbb4214e0c3d38": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4696fa195eaf41828276bae08a263a0c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "483e4fba58de4ed4be428b2826065293": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4854083ef2cf45fdbaa0111ae96b52d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4c1a51298ca348e69bc5e22406aa1fa2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4c4572808a8f4e4281b79995b23c611f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5a3c3725428942b7aba3d886ac3f18df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b981b8eea73447bcb3a17c6c3f669d97",
       "placeholder": "​",
       "style": "IPY_MODEL_4c1a51298ca348e69bc5e22406aa1fa2",
       "value": " 456k/456k [00:00&lt;00:00, 1.89MB/s]"
      }
     },
     "5a6b4bf70bd2416ebdbb119dd861d2e2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5b7dbe372e324e10a2b3a0ec174f44fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_36c74edf53f64d81bcc07b0e2b0fe444",
       "placeholder": "​",
       "style": "IPY_MODEL_159ed5f4e0e348b2984629d7b0b958ff",
       "value": "Downloading model.safetensors: 100%"
      }
     },
     "5c855a6379f24eab925c21fad6580df8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c57b1e0742b94c0c9f93cfed17f2d3f6",
       "max": 482,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_36982ad90e3a4b618f6efd3cae9108b5",
       "value": 482
      }
     },
     "60873259ebc74ba1bd543e93c35ca382": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_483e4fba58de4ed4be428b2826065293",
       "placeholder": "​",
       "style": "IPY_MODEL_c018c138802c4c489e9901050a7d2acc",
       "value": "Downloading (…)olve/main/merges.txt: 100%"
      }
     },
     "8593c9178b7c408ca02f4d4e18d11b09": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8748fc68f316443d9bb87545cf3fac30": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d1b453bf03e64485b800e452ff64ecc7",
       "placeholder": "​",
       "style": "IPY_MODEL_074c9d3d29e645d388743b1943f24421",
       "value": "Downloading (…)olve/main/vocab.json: 100%"
      }
     },
     "9ba01c5cd4e34d24b6ef1329281d0b82": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f0965483d8a547a48df8d63a9d6bd974",
       "placeholder": "​",
       "style": "IPY_MODEL_05b4dcc081a9431792cc04b2fc5c2f21",
       "value": " 899k/899k [00:00&lt;00:00, 2.75MB/s]"
      }
     },
     "a58f9e8554dd497b9096cb0abba83b70": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a734f3e3fc1f41ffa7e6df985fcf8519": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2c9bfbc6f34d4e53b2d2cc37fb2515ab",
       "placeholder": "​",
       "style": "IPY_MODEL_1dea960f8dbd47748d36c15c2066dbd1",
       "value": " 482/482 [00:00&lt;00:00, 37.6kB/s]"
      }
     },
     "b020975771c04098aafa4133091426b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b981b8eea73447bcb3a17c6c3f669d97": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ba22dd5390ee4393a9bf94aa2f3a4aa6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "bc2330c581554fae8d11e88d91544e7a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_46025fc4fd5f4fe89afbb4214e0c3d38",
       "max": 1421700479,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4854083ef2cf45fdbaa0111ae96b52d0",
       "value": 1421700479
      }
     },
     "bc4c4afeecdf4b9d86b396474404cbba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c018c138802c4c489e9901050a7d2acc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c1ba4512b5eb4f81bf3da765047cc5c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5b7dbe372e324e10a2b3a0ec174f44fc",
        "IPY_MODEL_bc2330c581554fae8d11e88d91544e7a",
        "IPY_MODEL_17a51cedfeaa4ef4bf72da7748099364"
       ],
       "layout": "IPY_MODEL_5a6b4bf70bd2416ebdbb119dd861d2e2"
      }
     },
     "c57b1e0742b94c0c9f93cfed17f2d3f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c877632270234002b4bc965b7c9066a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4696fa195eaf41828276bae08a263a0c",
       "placeholder": "​",
       "style": "IPY_MODEL_ba22dd5390ee4393a9bf94aa2f3a4aa6",
       "value": "Downloading (…)lve/main/config.json: 100%"
      }
     },
     "d0274c111c2f48a581b031975e94c90b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d1b453bf03e64485b800e452ff64ecc7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f0965483d8a547a48df8d63a9d6bd974": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f8e3dea30c724373a1c12565c4ad24e1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
